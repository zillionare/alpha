{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4d3f7f",
   "metadata": {},
   "source": [
    "# 使用信号处理函数-argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "150532e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from alpha.notebook import *\n",
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 999\n",
    "from alpha.core.rsi_stats import rsi30, rsiday\n",
    "import talib\n",
    "\n",
    "await init_notebook()\n",
    "\n",
    "shday = await get_bars(\"000001.XSHG\", 100, '1d', '2021-11-5 15:00')\n",
    "shmin = await get_bars(\"000001.XSHG\", 220, '30m', '2021-11-05 15:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_and_valley(bars):\n",
    "    ma = moving_average(bars[\"close\"], 10)\n",
    "    \n",
    "    peak_indexes = argrelextrema(ma, np.greater)\n",
    "    peaks = peak_indexes[0]\n",
    "\n",
    "    # Find valleys(min).\n",
    "    valley_indexes = argrelextrema(ma, np.less)\n",
    "    valleys = valley_indexes[0]\n",
    "\n",
    "    assert abs(len(peaks) - len(valleys)) <= 1\n",
    "    \n",
    "    bars = bars[9:]\n",
    "    # Plot main graph.\n",
    "    (fig, ax) = plt.subplots()\n",
    "    ax.plot(np.arange(len(bars)), bars[\"close\"], color='c')\n",
    "    ax.plot(np.arange(len(bars)), ma, color='b')\n",
    "\n",
    "    # Plot peaks.\n",
    "    peak_x = peaks\n",
    "    peak_y = bars['close'][peak_x]\n",
    "    ax.plot(peak_x, peak_y, 'gv', label=\"Peaks\")\n",
    "\n",
    "    # Plot valleys.\n",
    "    valley_x = valleys\n",
    "    valley_y = bars['close'][valley_x]\n",
    "    ax.plot(valley_x, valley_y, 'r^', label=\"Valleys\")\n",
    "     \n",
    "    trades = []\n",
    "    gains = 1\n",
    "    order = None\n",
    "\n",
    "    vertex = sorted([*peaks, *valleys])\n",
    "    for x in vertex:\n",
    "        close = bars[\"close\"]\n",
    "        buy = x in valleys\n",
    "        sell = x in peaks\n",
    "        if buy and order is None:\n",
    "            order = {\n",
    "                \"buy\": close[x] * 0.5 + close[x+1] * 0.5,\n",
    "                \"buy_at\": bars[\"frame\"][x+1]\n",
    "            }\n",
    "\n",
    "        elif sell and order:\n",
    "            buy = order[\"buy\"]\n",
    "            sell = close[x+1] * 0.5 + close[x] * 0.5,\n",
    "            gain = sell / buy\n",
    "            order.update({\n",
    "                \"sell\": sell,\n",
    "                \"sell_at\": bars[\"frame\"][x+1],\n",
    "                \"gain\": gain\n",
    "            })\n",
    "\n",
    "            gains *= gain\n",
    "            trades.append(order)\n",
    "            order = None\n",
    "\n",
    "    return gains - 1, trades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ab22e",
   "metadata": {},
   "source": [
    "# 指数30分钟拐头报警"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a89ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "minclose = shmin[\"close\"]\n",
    "minframe = shmin[\"frame\"]\n",
    "ma = moving_average(minclose, 5)\n",
    "\n",
    "# align frame with ma\n",
    "close = close[4:]\n",
    "frame = frame[4:]\n",
    "bars = sh[4:]\n",
    "\n",
    "\n",
    "local_ma = argrelextrema(ma, np.greater, order=5)[0]\n",
    "local_mi = argrelextrema(ma, np.less, order=5)[0]\n",
    "\n",
    "plt.plot(ma)\n",
    "plt.plot(local_ma, ma[local_ma], 'gv')\n",
    "plt.plot(local_mi, ma[local_mi], 'r^')\n",
    "for i in local_ma:\n",
    "    plt.text(i, ma[i], f\"{str(frame[i])[5:13]}_{i}\")    \n",
    "for i in local_mi:\n",
    "    plt.text(i, ma[i], f\"{str(frame[i])[5:13]}_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba1ceb",
   "metadata": {},
   "source": [
    "# 抛物线转向\n",
    "\n",
    "股票的均线形态常常会出现类似于抛物线的向下、向下转向，尤其以指数为甚。但研究表明，抛物线拟合中容易出现错误信号。准确率不高，看如何提升？\n",
    "\n",
    "如果连续几个周期出现a一致，而dist每次加1，则说明这个pattern比较稳定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabolic_features(ts, rng=7, ma_win=5, calc_ma=True):\n",
    "    \"\"\"检测`ts`代表的最后7个周期的均线中，是否存在抛物线特征。\n",
    "    \"\"\"\n",
    "    if calc_ma:\n",
    "        ts = moving_average(ts, ma_win)\n",
    "\n",
    "    ts_ = ts[-rng:]\n",
    "    (a, b, c), pmae = polyfit(ts_)\n",
    "\n",
    "    # predict till next frame\n",
    "    y_ = np.polyval((a,b,c), np.arange(rng + 1))\n",
    "\n",
    "    # uncomment this to draw the lines\n",
    "    # plt.plot(np.arange(len(ts)-rng, len(ts)), y_)\n",
    "    # plt.plot(ts)\n",
    "\n",
    "    vx = round(-b/(2*a),1)\n",
    "    \n",
    "    next_ts = reverse_moving_average(y_, rng, ma_win)\n",
    "    pred_roc = next_ts/ts[-1] - 1\n",
    "    \n",
    "    return np.sign(pred_roc), pred_roc, rng - vx, round(a, 4), round(pmae, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-10, -1):\n",
    "    print(minframe[i], parabolic_features(minclose[:i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe0e6b2",
   "metadata": {},
   "source": [
    "# 机器学习模型\n",
    "\n",
    "目标： 需要能判断\n",
    "\n",
    "33 10-25 10:00 底\n",
    "\n",
    "10-26 10:30 顶 RSI\n",
    "\n",
    "10-29 10:00 底 RSI\n",
    "\n",
    "11-02 10:00 顶 抛物线转向？要求11：00能发出信号\n",
    "\n",
    "11-03 13:30 底\n",
    "\n",
    "11-03 14:30 底 RSI底背离\n",
    "\n",
    "11-04 15:00 顶 抛物线转向？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb5dcd",
   "metadata": {},
   "source": [
    "## 数据标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d731146f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734 738\n"
     ]
    }
   ],
   "source": [
    "shmin_12000 = await get_bars(\"000001.XSHG\", 12000, '30m', end=\"2011-11-05 15:00\")\n",
    "peaks, valleys = peaks_and_valleys(shmin_12000[\"close\"], min_altitude_ratio=1e-3)\n",
    "\n",
    "print(len(peaks), len(valleys))\n",
    "\n",
    "peak_frames = [shmin_12000[p]['frame'] for p in peaks]\n",
    "valley_frames = [shmin_12000[p]['frame'] for p in valleys]\n",
    "\n",
    "data = {\n",
    "    \"bars\": shmin_12000,\n",
    "    \"peaks\": peaks,\n",
    "    \"valleys\": valleys\n",
    "}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"/apps/alpha/data/sh_30m_pv_labbelled.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32570bc8",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84648b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.18026936e-01  9.10000000e-01  9.30000000e-01  7.50000000e-01\n",
      "  7.91300000e+01  7.98300000e+01  6.73700000e+01  1.00000000e+00\n",
      "  8.55746492e-03  3.47000000e+01  1.56300000e-01  2.10000000e-04\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.24630737e-03\n",
      "  2.23994255e-03  0.00000000e+00 -1.00000000e+00 -1.00000000e+00\n",
      " -1.00000000e+00]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "features = []\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for i in peaks:\n",
    "    if i < 100 or i == 12000-1:\n",
    "        continue\n",
    "        \n",
    "    feature, desc = reversal_features(\"000001.XSHG\", shmin_12000[i-99:i+1], FrameType.MIN30, peak_altitude=1e-3)\n",
    "    features.append([*feature, 0, i])\n",
    "    \n",
    "for i in valleys:\n",
    "    if i < 100 or i == 12000-1:\n",
    "        continue\n",
    "        \n",
    "    feature, desc = reversal_features(\"000001.XSHG\", shmin_12000[i-99:i+1], FrameType.MIN30, peak_altitude=1e-3)\n",
    "    features.append([*feature, 1, i])\n",
    "    \n",
    "excluded = set(peaks)\n",
    "excluded.update(valleys)\n",
    "\n",
    "for i in random.sample(range(100, 9999), 1000):\n",
    "    if i not in excluded:\n",
    "        feature, desc = reversal_features(\"000001.XSHG\", shmin_12000[i-99:i+1], FrameType.MIN30, peak_altitude=1e-3)\n",
    "        features.append([*feature, 2, i])\n",
    "        \n",
    "features = np.array(features)\n",
    "total = len(features)\n",
    "train_indices = random.sample([i for i in range(total)], int(0.8 * total ))\n",
    "test_indices = list(set(np.arange(total)) - set(train_indices))\n",
    "\n",
    "X_train = features[train_indices][:,0:-2]\n",
    "y_train = features[train_indices][:,-2].astype('i4')\n",
    "meta_train = features[train_indices][:,-1].astype('i4')\n",
    "\n",
    "X_test = features[test_indices][:,0:-2]\n",
    "y_test = features[test_indices][:,-2].astype('i4')\n",
    "meta_test = features[test_indices][:,-1].astype('i4')\n",
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3768947",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric='mlogloss', gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=n...\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0xffff174d8e20>,\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0xffff174f1070>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0xffff174f1340>,\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0xffff174f14f0>},\n",
       "                   random_state=78, return_train_score=True, verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "\n",
    "model = XGBClassifier(eval_metric='mlogloss',use_label_encoder=False)\n",
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.7, 0.3),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.01, 1),\n",
    "    \"max_depth\": randint(2, 6),\n",
    "    \"n_estimators\": randint(80, 150),\n",
    "    \"subsample\": uniform(0.6, 0.4),\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions=params,\n",
    "    random_state=78,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=4,\n",
    "    return_train_score=True,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758318f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "model = search.best_estimator_\n",
    "preds = model.predict(X_test)\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if i == 20:\n",
    "        break\n",
    "    if y_test[i] != preds[i]:\n",
    "        pos = int(meta_test[i])\n",
    "        \n",
    "        cs = Candlestick({'30m': [5, 10, 20, 30]}, n_plot_bars=60)\n",
    "        bars = shmin_12000[pos-50:pos+10]\n",
    "\n",
    "        vec, desc = reversal_features(\"000001.XSHG\", bars[:-9], FrameType.MIN30, peak_altitude=1e-3)\n",
    "        \n",
    "        features = [f\"{d}: {v:.2f}\" for d, v in zip(desc, vec)]\n",
    "        plt.text(0, 0, \"\\n\".join(features))\n",
    "        \n",
    "        cs.plot_bars(bars, title = f\"True: {y_test[i]}/ Pred: {preds[i]}\", signals=[(50, 'x', 'r')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3211c7e4",
   "metadata": {},
   "source": [
    "# revisions\n",
    "v1: \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.70      0.81      0.75       158\n",
    "           1       0.68      0.76      0.72       134\n",
    "           2       0.57      0.44      0.50       177\n",
    "\n",
    "    accuracy                           0.66       469\n",
    "   macro avg       0.65      0.67      0.66       469\n",
    "weighted avg       0.65      0.66      0.65       469\n",
    "\n",
    "\n",
    "[x] v2: parab_vx 取值范围过宽，可能导致收敛困难，应该限制在-win:win之间。\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.64      0.79      0.71       144\n",
    "           1       0.71      0.85      0.77       143\n",
    "           2       0.62      0.42      0.50       185\n",
    "\n",
    "    accuracy                           0.66       472\n",
    "   macro avg       0.66      0.68      0.66       472\n",
    "weighted avg       0.65      0.66      0.65       472\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/aaron/zillionare/alpha/models/reversal-v1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d33866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.00118"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.0002*0.9+1.656+1.656+1.656+3.312+74.521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e265f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpha",
   "language": "python",
   "name": "alpha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "224px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
